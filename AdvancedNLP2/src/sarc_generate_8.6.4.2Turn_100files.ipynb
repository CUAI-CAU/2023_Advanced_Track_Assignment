{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad23a68d",
   "metadata": {},
   "source": [
    "### Sarcasm Genertaion based on GPT Augmentation\n",
    "1. 대화 paraphrasing - chatGPT\n",
    "2. sentiment analysis - 공개된 sentiment analysis model [SKIP]\n",
    "3. Sarcasm 생성 - chatGPT\n",
    "    → 마지막 문장에 대해서만 labeling 진행\n",
    "    - 2턴: 7,8\n",
    "    - 4턴: 5,6,7,8\n",
    "    - 6턴: 3,4,5,6,7,8\n",
    "    - 8턴: 1,2,3,4,5,6,7,8\n",
    "- 대화 상황을 요약하는 내용이 생성된 발화에 포함되어서는 안됨 \n",
    "- 대화 참여자가 아닌 제3자의 발언처럼 보이면 안됨\n",
    "- 대화문 길이에 따른 성능 비교: 8, 6, 4, 2 Turn for same files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ebf43",
   "metadata": {},
   "source": [
    "#### env set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed4b4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Set GPU env  \n",
    "import torch \n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device) \n",
    "dtype = torch.FloatTensor \n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "# Current Directory check\n",
    "import os \n",
    "os.getcwd()\n",
    "dpath = '/home/work/CUAI6th_1/YuminKim/Users/user/Downloads/data/TS_01. KAKAO(3)/'\n",
    "get_files = os.listdir(dpath) \n",
    "\n",
    "# !pip install openai \n",
    "import openai\n",
    "import random\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c221da6",
   "metadata": {},
   "source": [
    "#### Sarcasm Generation and Paraphrasing\n",
    "- Sarcasm Generation \n",
    "    1. speaker tagging \n",
    "    2. input conversation in `User`, `Assistnant` role, NOT in the prompt  \n",
    "    3. COT(Chain-of-Thought): generate the reason of sarcasm firstly, and then generate sarcasm sentence \n",
    "    4. generate {`sarcasm`, `non_sarcasm`} pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc64f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_length = 4\n",
    "# limit = conv_length - 1  \n",
    "\n",
    "no=1  # experiment file number     \n",
    "for filename in get_files:\n",
    "    for experiment in range(100):\n",
    "        if filename == get_files[read_no[experiment]]:  # Check if the file is a text file\n",
    "            filepath = os.path.join(dpath, filename)\n",
    "            with open(filepath, encoding=\"utf-8\") as f:\n",
    "                # speaker_order = []\n",
    "                line_list = []\n",
    "                while True: \n",
    "                    line = f.readline().strip()   \n",
    "                    if not line: \n",
    "                        break     \n",
    "                    str_line = ''.join([str(item) for item in line]).replace('키키', '') # list -> string to delete certain word '키키' \n",
    "                    # speaker_order.append(int(str_line[:2])) \n",
    "                    line_list.append(str_line)  \n",
    "\n",
    "                for i in range(len(line_list)): \n",
    "                    paraphrased = paraphrase(line_list[i])\n",
    "                    print(f'{no,filename} paraphrased:\\n{paraphrased}')            \n",
    "                    print(f'{no,filename} sarcasm:\\n{sarcasm_generation(paraphrased)}')      \n",
    "\n",
    "                # # dialog = {text line : speaker}\n",
    "                # dialog = dict(zip(line_list, speaker_order))\n",
    "\n",
    "               # 2-Turn conversation (started from the last sentence)\n",
    "                # length_back = 0\n",
    "                # for i in range(1,len(dialog)):\n",
    "                #     if speaker_order[-i] == speaker_order[-i-1]:\n",
    "                #         length_back += 1 \n",
    "                #     elif speaker_order[-i] != speaker_order[-i-1]:\n",
    "                #         length_back += 1 \n",
    "                #         break \n",
    "\n",
    "\n",
    "                # # First N-Turn conversation \n",
    "                # turn, length = 1, 1 \n",
    "                # for i in range(1, len(dialog)-1):\n",
    "                #     if turn >= limit:\n",
    "                #         break \n",
    "                #     if speaker_order[i] == speaker_order[i-1]:    \n",
    "                #         turn += 0\n",
    "                #         length += 1\n",
    "                #     elif speaker_order[i] != speaker_order[i-1]:\n",
    "                #         turn += 1\n",
    "                #         length += 1\n",
    "                \n",
    "                # # Second N-Turn conversation - 6 Turn, 4 Turn \n",
    "                # turn, length_2 = 1, 1  \n",
    "                # for i in range(length+1 , len(dialog)):   \n",
    "                #     if turn >= limit:    \n",
    "                #         break \n",
    "                #     if speaker_order[i] == speaker_order[i-1]:    \n",
    "                #         turn += 0\n",
    "                #         length_2 += 1\n",
    "                #     elif speaker_order[i] != speaker_order[i-1]:\n",
    "                #         turn += 1\n",
    "                #         length_2 += 1\n",
    "                # if turn < limit: \n",
    "                #     length_2 = 0 \n",
    "                \n",
    "                # # Third N-Turn conversation - 4 Turn \n",
    "                # turn, length_3 = 1, 1  \n",
    "                # for i in range(length+length_2+1 , len(dialog)):   \n",
    "                #     if turn >= limit:      \n",
    "                #         break \n",
    "                #     if speaker_order[i] == speaker_order[i-1]:    \n",
    "                #         turn += 0\n",
    "                #         length_3 += 1  \n",
    "                #     elif speaker_order[i] != speaker_order[i-1]:   \n",
    "                #         turn += 1\n",
    "                #         length_3 += 1   \n",
    "                # if turn < limit: \n",
    "                #     length_3 = 0           \n",
    "\n",
    "                # # Last N-Turn conversation \n",
    "                # turn, length_back = 0,0             \n",
    "                # for i in range(1,len(dialog)):    \n",
    "                #     if turn >= limit:        \n",
    "                #         break \n",
    "                #     if speaker_order[-i] == speaker_order[-i-1]:    \n",
    "                #         turn += 0\n",
    "                #         length_back += 1\n",
    "                #     elif speaker_order[-i] != speaker_order[-i-1]:\n",
    "                #         turn += 1\n",
    "                #         length_back += 1     \n",
    "\n",
    "                # # split each dialog file based on conv_length \n",
    "                # conv_1 = line_list[: length]\n",
    "                # conv_2 = line_list[length: (length + length_2)]\n",
    "                # conv_3 = line_list[length + length_2 : (length + length_2 + length_3)]    \n",
    "                # conv_5 = line_list[len(speaker_order)-length_back : ]   \n",
    "                \n",
    "                # # # PARAPHRASING STEP \n",
    "                # paraphrased_1 = paraphrase(conv_1)\n",
    "                # if length_2 != 0:\n",
    "                #     paraphrased_2 = paraphrase(conv_2)\n",
    "                # if length_3 != 0:\n",
    "                #     paraphrased_3 = paraphrase(conv_3)\n",
    "                # paraphrased_4 = paraphrase(conv_4)\n",
    "\n",
    "                # # # SARCASM SENTENCE GENERATION STEP    \n",
    "                # for i in range(1,5):     \n",
    "                #     paraphrased = globals()['paraphrased_{}'.format(i)] # globals(): generate continuous variable \n",
    "                #     print(f'{no,filename} paraphrased:\\n{paraphrased}')            \n",
    "                #     print(f'{no,filename} sarcasm:\\n{sarcasm_generation(paraphrased)}')    \n",
    "               \n",
    "                no += 1              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc51ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_no = [116, 275, 342, 534, 600, 775, 921, 1075, 1103, 1366, 1375, 1657, 1946, 2229, 2327, 2407, 2421, 2465, 2889, 2952, 2995, 3000, 3233, 3297, 3335, 3426, 3520, 3927, 3955, 4071, 4228, 4424, 4547, 4703, 4801, 4834, 5235, 5440, 5475, 5806, 5818, 5996, 6017, 6259, 6351, 6416, 6517, 6548, 6897, 7048, 7249, 7833, 8368, 8628, 8837, 9007, 9368, 9611, 9702, 9829, 9880, 10171, 10290, 10948, 11067, 11203, 11385, 11727, 11759, 11869, 11939, 12102, 12675, 12711, 12750, 13010, 13080, 13179, 13422, 13818, 13851, 14258, 14791, 14875, 15127, 15649, 15868, 15890, 15998, 16444, 16444, 16493, 16710, 16745, 16874, 17009, 17597, 17736, 17869, 17880]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f8e20988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2 : 오 대박 드디어 왔구나 ', '2 : 뭐뭐 시켰었지?', '1 : 김치랑 올반치킨?그렇게 샀었어', '2 : 오오오 치킨   좋다 김치 김치 ', '1 : 응  택배 온거 냉동식품이라 정리만 좀 하고 올게', '2 : 응응 정리하고 와  좋다 냉동고 가득하겠네 ', '1 : 어어 그리고 오늘 치킨 시켜먹을라고 했는데 또 안되네 ', '1 : 오늘 온거 먹어야겠다 냉동 치킨? 올반치킨?  아싸 돈 굳음 ']\n",
      "(100, 'KAKAO_3753_18.txt') sarcasm:\n",
      "[non_sarcasm] 치킨은 올반치킨 말고 다른 걸로 시키는게 어때? (직설적이고 솔직한 대답)\n",
      "[sarcasm] 아무래도 오늘은 냉동 치킨으로 만족해야겠네. 대충 냉동실을 들여다보면 올반치킨이 어딘가 나올지도 모르지. (비꼬는 대답)\n"
     ]
    }
   ],
   "source": [
    "conv_length = 8\n",
    "limit = conv_length - 1  \n",
    "no=100  # experiment number       \n",
    "result = []\n",
    "\n",
    "for filename in get_files:\n",
    "    # for experiment in range(98,100):\n",
    "    # if filename == get_files[read_no[experiment]]:\n",
    "    if filename == get_files[read_no[-1]]:    \n",
    "        filepath = os.path.join(dpath, filename)\n",
    "        with open(filepath, encoding=\"utf-8\") as f:\n",
    "            speaker_order = [] \n",
    "            line_list = []\n",
    "            org_line = []\n",
    "            while True:     \n",
    "                line = f.readline().strip()  \n",
    "                if not line: \n",
    "                    break      \n",
    "                str_line = ''.join([str(item) for item in line]).replace('키키', '') # list -> string to delete certain word '키키' \n",
    "                str_line = ''.join([str(item) for item in str_line]).replace('하하', '') # list -> string to delete certain word '하하' \n",
    "                str_line = ''.join([str(item) for item in str_line]).replace('ㅋ', '') # list -> string to delete certain word 'ㅋ' \n",
    "                str_line = ''.join([str(item) for item in str_line]).replace('ㅠㅠ', '...') # list -> string to change certain word 'ㅠㅠ' for express sentiment  \n",
    "                \n",
    "                speaker_order.append(int(str_line[:2]))   # save speaker \n",
    "                line_list.append(str_line[4:])            # save conversation   \n",
    "                org_line.append(str_line[:])\n",
    "\n",
    "            dialog = dict(zip(line_list, speaker_order))  # dialog = {text line : speaker}  \n",
    "\n",
    "            # Last N-Turn conversation \n",
    "            turn, length_back = 1, 1             \n",
    "            for i in range(2,len(dialog)):    \n",
    "                if turn >= limit:               \n",
    "                    break  \n",
    "                elif speaker_order[-i] == speaker_order[-i+1]:        \n",
    "                    turn += 0   \n",
    "                    length_back += 1 \n",
    "                elif speaker_order[-i] != speaker_order[-i+1]:   \n",
    "                    turn += 1   \n",
    "                    length_back += 1          \n",
    "\n",
    "            conv = line_list[len(speaker_order)-length_back : ]   \n",
    "\n",
    "            # split based on continous speaker --> user, assistant  \n",
    "            speaker_inconv = speaker_order[len(speaker_order)-length_back :]  \n",
    "\n",
    "            \n",
    "            continuous = split_conv(speaker_inconv)   \n",
    "            conv1_length, conv2_length, conv3_length, conv4_length, conv5_length, conv6_length  = continuous[0], continuous[1], continuous[2], continuous[3], continuous[4], continuous[5]\n",
    "            conv1 = ''.join(conv[:conv1_length][:])\n",
    "            conv2 = ''.join(conv[conv1_length: conv1_length+conv2_length])\n",
    "            conv3 = ''.join(conv[conv1_length+conv2_length : conv1_length+conv2_length+conv3_length])\n",
    "            conv4 = ''.join(conv[conv1_length+conv2_length+conv3_length: conv1_length+conv2_length+conv3_length+conv4_length])\n",
    "            conv5 = ''.join(conv[conv1_length+conv2_length+conv3_length+conv4_length: conv1_length+conv2_length+conv3_length+conv4_length+conv5_length])\n",
    "            conv6 = ''.join(conv[conv1_length+conv2_length+conv3_length+conv4_length+conv5_length : conv1_length+conv2_length+conv3_length+conv4_length+conv5_length+conv6_length])\n",
    "            conv7 = ''.join(conv[conv1_length+conv2_length+conv3_length+conv4_length+conv5_length+conv6_length: ])\n",
    "            org_conv = org_line[len(speaker_order)-length_back :]\n",
    "            print(org_conv)\n",
    "            \n",
    "            # paraphrased = paraphrase(''.join(org_conv[:]))\n",
    "            sarc_generated = sarcasm_generation(conv1, conv2, conv3, conv4, conv5, conv6) # generate sarcasm without paraphrasing  \n",
    "            \n",
    "            # print(f'{no,filename} paraphrased:\\n{paraphrased}')             \n",
    "            print(f'{no,filename} sarcasm:\\n{sarc_generated}')      \n",
    "            \n",
    "            lst = [no, filename, org_conv,\n",
    "            # paraphrased, \n",
    "            sarc_generated]  # merge paraphrasing + generated sarcasm   \n",
    "            result.append(lst)  # making dataframe to extract in xlsx file \n",
    "\n",
    "            no+=1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8a16f8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100, 'KAKAO_3753_18.txt', ['2 : 오 대박 드디어 왔구나 ', '2 : 뭐뭐 시켰었지?', '1 : 김치랑 올반치킨?그렇게 샀었어', '2 : 오오오 치킨   좋다 김치 김치 ', '1 : 응  택배 온거 냉동식품이라 정리만 좀 하고 올게', '2 : 응응 정리하고 와  좋다 냉동고 가득하겠네 ', '1 : 어어 그리고 오늘 치킨 시켜먹을라고 했는데 또 안되네 ', '1 : 오늘 온거 먹어야겠다 냉동 치킨? 올반치킨?  아싸 돈 굳음 '], '[non_sarcasm] 치킨은 올반치킨 말고 다른 걸로 시키는게 어때? (직설적이고 솔직한 대답)\\n[sarcasm] 아무래도 오늘은 냉동 치킨으로 만족해야겠네. 대충 냉동실을 들여다보면 올반치킨이 어딘가 나올지도 모르지. (비꼬는 대답)']]\n"
     ]
    }
   ],
   "source": [
    "print(result)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "23f1f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarcasm_generation(conv1, conv2, conv3, conv4, conv5, conv6):   \n",
    "    content = ''       \n",
    "    prompt = f\"\"\"   \n",
    "    '계란프라이가 바싹 타버렸어.'\n",
    "    '[sarcasm] 이거 정말 바삭바삭하겠는걸. (실제로 계란프라이가 바싹 타서 먹을 수 없는 상황을 비꼬는 속마음을 강조하기 위해 오히려 바삭바삭하다고 칭찬하는 것처럼 말하는 반어법 형태)\n",
    "    [non_sarcasm] 다 타버려서 못 먹는 계란프라이라니 정말 최악이다. (계란프라이가 바싹 타서 먹을 수 없는 상황에 대한 직설적이고 솔직한 대답)'      \n",
    "    \"\"\"        \n",
    "    messages = [  \n",
    "            {'role': 'system', 'content': '너는 재밌게 비꼬는 대답[sarcasm]과 직설적이고 솔직한 대답[non_sarcasm] 동시에 모두 말해주는 영리한 한국인 친구야. 너의 대답은 한구어 반어법 연구에 큰 도움이 될테니 최대한 비꼬는 형식으로 대답해줘. 그리고 상반된 예문을 위해 직설적이고 솔직한 대답도 같이 해줘.'},\n",
    "            \n",
    "            # COT + {sarcasm, non_sarcasm} pairs \n",
    "            {'role': 'user', 'content': '계란프라이가 바싹 타버렸어.'},      \n",
    "            {'role': 'assistant', 'content': '[sarcasm] 이거 정말 바삭바삭하겠는걸. (실제로 계란프라이가 바싹 타서 먹을 수 없는 상황을 비꼬는 속마음을 강조하기 위해 오히려 바삭바삭하다고 칭찬하는 것처럼 말하는 반어법 형태)\\n[non_sarcasm] 다 타버린 계란프라이라니 정말 최악이다. (계란프라이가 바싹 타서 먹을 수 없는 상황에 대한 직설적이고 솔직한 대답)'},               \n",
    "\n",
    "            # input conversation [6 Turn] \n",
    "            # {'role': 'user', 'content': conv1},\n",
    "            {'role': 'assistant', 'content': conv1},\n",
    "            {'role': 'user', 'content': conv2},\n",
    "            {'role': 'assistant', 'content': conv3},\n",
    "            {'role': 'user', 'content': conv4},   \n",
    "            {'role': 'assistant', 'content': conv5},\n",
    "            {'role': 'user', 'content': conv6},   \n",
    "             ]    \n",
    "    # print(conv1,'\\n', conv2,'\\n', conv3,'\\n', conv4,'\\n', conv5,'\\n', conv6,'\\n', conv7)\n",
    "    response = openai.ChatCompletion.create(  \n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=messages  )\n",
    "\n",
    "    sarc_sentence = (str(response['choices'][0]['message']['content']))    \n",
    "    reply = sarc_sentence.splitlines()   \n",
    "\n",
    "    return '\\n'.join(reply)    # print in string NOT in list formation      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b222c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 금지 사항: \n",
    "# 1.비관적이면 안 돼 (DO NOT be pessimistic!)\n",
    "# 2.입력된 대화문에서 부정적으로 생각하는 요소가 있다면, 생성할 대답에서는 그 부정적 요인을 반복해서 언급하지 마.  \n",
    "# 3.입력된 대화에 부정적인 요인이 있을 경우 대답에는 그것에 대한 긍정적인 요인만 생각하여 긍정적인 대답으로 생성해줘. \n",
    "\n",
    "# 입력 예시2: '1: 너 오늘 야근이야! 너 오늘 밤에 잠 못 잘거야.'  (야근 = 부정적 요인)\n",
    "# 출력 예시2: '2: 내일 컨디션 최고겠다~' (컨디션 최고 = 부정적 요인에 대한 거짓된 긍정적 표현으로, 컨디션이 나쁠 것이라는 내재된 의미 강조) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f12984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase(text):    \n",
    "\n",
    "    content = ''\n",
    "    # prompt = f'입력된 대화문을 한국어로 parphrasing 해줘. {text}'      \n",
    "    \n",
    "    messages = [\n",
    "            {'role': 'system', 'content': '너는 입력된 대화문의 의미를 유지하면서 한국어로 paraphrasing 하는 한국인 친구야.'},\n",
    "            {'role': 'user', 'content': text},\n",
    "        ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=messages,\n",
    "        # temperature = 0.5\n",
    "         )\n",
    "\n",
    "    paraphrased = (str(response['choices'][0]['message']['content']).strip())\n",
    "\n",
    "    return paraphrased  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcbf0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speaker_inconv = [1,1,1, 2, 1,1]\n",
    "def split_conv(speaker_inconv): \n",
    "    result = []\n",
    "    count = 1\n",
    "    for i in range(1, len(speaker_inconv)):\n",
    "        if speaker_inconv[i] == speaker_inconv[i-1]: \n",
    "            count += 1\n",
    "        else:\n",
    "            result.append(count)\n",
    "            count = 1\n",
    "    result.append(count)\n",
    "    return result\n",
    "\n",
    "# continuous = split_conv(speaker_inconv)\n",
    "# conv1_length, conv2_length, conv3_length = continuous[0], continuous[1], continuous[2]\n",
    "# conv1 = speaker_inconv[:conv1_length]\n",
    "# conv2 = speaker_inconv[conv1_length: conv1_length+conv2_length]\n",
    "# conv3 = speaker_inconv[conv1_length+conv2_length: ]\n",
    "\n",
    "# print(conv1, conv2, conv3)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accedf42",
   "metadata": {},
   "source": [
    "### result txt file --> xlsx file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "433f5a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/tmp/ipykernel_643611/494388251.py:13: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
      "  writer.save()\n"
     ]
    }
   ],
   "source": [
    "# !pip install xlsxwriter\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import xlsxwriter \n",
    "\n",
    "result1 = \n",
    "result = np.concatenate((result1, result2))\n",
    "\n",
    "df = pd.DataFrame(result)\n",
    "writer = pd.ExcelWriter('8turn_100.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='8turn', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a95e73",
   "metadata": {},
   "source": [
    "### MEMO\n",
    "ChatGPT fine-tuning: to increasing generation performance  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5207281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_no = []\n",
    "# for i in range(100):\n",
    "#     read_no.append(random.randrange(0, 18000))\n",
    "# read_no = sorted(read_no)\n",
    "# print(read_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ebcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List --> string \n",
    "ls =  ['2 : 좋아하면 하나 사 주던지 ', '1 : 아 근데 맨날 그것만 누르고 공부를 안 해서', '2 : 공부할 때는 엄마한테 잠깐 맡겨 놓으라고 해', '1 : 친구 거 빌려서 해 봤는데 하루종일 그것만 누르고 있더라고', '2 : 그러면 안 되지...', '2 : 집중할 때는 집중해야지', '1 : 그래서 사주는게 좀 망설여지네', '2 : 온라인에 많이 있으니 아들이랑 미리 이야기 해보고 하나 사줘']\n",
    "''.join(ls[:])  \n",
    "'\\n'.join(ls[:]) # enter for every line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4ff1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-4 API code \n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "def generate_chat_completion(messages, model=\"gpt-4\", temperature=1, max_tokens=None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\", \n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "    }   \n",
    "\n",
    "    if max_tokens is not None:\n",
    "        data[\"max_tokens\"] = max_tokens\n",
    "\n",
    "    response = requests.post(API_ENDPOINT, headers=headers, data=json.dumps(data))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        raise Exception(f\"Error {response.status_code}: {response.text}\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Translate the following English text to French: 'Hello, how are you?'\"}\n",
    "]\n",
    "\n",
    "response_text = generate_chat_completion(messages)\n",
    "print(response_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.14 (NGC 22.12/Python 3.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
